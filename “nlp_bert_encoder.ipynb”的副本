{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"“nlp_bert_encoder.ipynb”的副本","provenance":[{"file_id":"1mgEc0XYPCjNn9LGveThUXZSgOby6BOsK","timestamp":1618479112394}],"collapsed_sections":["-E7lQPL7adyF"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aba78168ddc34bfb89046f5c5907cfdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d4e312228a804ded991d18fc6923cd13","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d91468761b514d7786cc608f21ac1d9e","IPY_MODEL_cac6513fd8ee44d9b2e6198ea0a9e10f"]}},"d4e312228a804ded991d18fc6923cd13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d91468761b514d7786cc608f21ac1d9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a24bb805715549c39df11c1c4e7bd825","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75cc15f010a7455db680185a592e06ef"}},"cac6513fd8ee44d9b2e6198ea0a9e10f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7fc94fb260a443b0a6d95eb58f9ab600","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:20&lt;00:00, 20.7B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_227807e216ab4423b6e0b74b1b315752"}},"a24bb805715549c39df11c1c4e7bd825":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75cc15f010a7455db680185a592e06ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7fc94fb260a443b0a6d95eb58f9ab600":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"227807e216ab4423b6e0b74b1b315752":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf1e8d518b42471eaa218c08c67db61e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ac661961cd5149f695626e12b01349f5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c9236e79f08c4fe78a0d729ebfb2f1b1","IPY_MODEL_8f68f723318e483595b9a0b8656c7bca"]}},"ac661961cd5149f695626e12b01349f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9236e79f08c4fe78a0d729ebfb2f1b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1242015429f441a691891e89fff1b6c1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_094b7cf8989c443ba84c8a743c47540e"}},"8f68f723318e483595b9a0b8656c7bca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_17c92e5b084e46e0b3d3a7f5e4093f56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:19&lt;00:00, 12.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc5bca2ff7174411843c44de011fca3a"}},"1242015429f441a691891e89fff1b6c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"094b7cf8989c443ba84c8a743c47540e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17c92e5b084e46e0b3d3a7f5e4093f56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc5bca2ff7174411843c44de011fca3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5519c8b78cfb45e78ee94adb18ba6674":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5c1abdb98f644abbab14428defeb1625","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8db7887266a84b6d9089c961adf121cc","IPY_MODEL_6615fddc83ae401bbca013ee4fc8e6f8"]}},"5c1abdb98f644abbab14428defeb1625":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8db7887266a84b6d9089c961adf121cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6490e2c3997c496c8182237790c8170c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2810194798a94d36818d35bf48bf0d60"}},"6615fddc83ae401bbca013ee4fc8e6f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f1e3bdf0d7a34b359e2a03d782098e97","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:03&lt;00:00, 148kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb05c012d1424a8394e302d76f560fb8"}},"6490e2c3997c496c8182237790c8170c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2810194798a94d36818d35bf48bf0d60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1e3bdf0d7a34b359e2a03d782098e97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb05c012d1424a8394e302d76f560fb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4408c96aa46d446d9fd03bdaab1d0705":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7dd790503f4244708d11e77ab8b37103","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e7fcb8a54f1f4a50ab3418de1af07201","IPY_MODEL_1fc8d8f682c84bec80192f8026437727"]}},"7dd790503f4244708d11e77ab8b37103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7fcb8a54f1f4a50ab3418de1af07201":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_14713e8482ce4268a6d2691f5d10f3d6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f72923edaee244799bd4d288c0ce047a"}},"1fc8d8f682c84bec80192f8026437727":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e728dc54cb0c4159b467666e6e8e881f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:13&lt;00:00, 2.02B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b11a5359c03341c8995ff5e62d4b5b4e"}},"14713e8482ce4268a6d2691f5d10f3d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f72923edaee244799bd4d288c0ce047a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e728dc54cb0c4159b467666e6e8e881f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b11a5359c03341c8995ff5e62d4b5b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"948fbb8fd4554c65bb4d2b9e5793bfcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6bdd72fc2e0d4dd4b60b5dc0eedf22c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14e68033d30b4fab8bff1b3057211f80","IPY_MODEL_c46b34c68bc34a519c9e0b39352b28b9"]}},"6bdd72fc2e0d4dd4b60b5dc0eedf22c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14e68033d30b4fab8bff1b3057211f80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3ded4c13a32f4fdda7a269e22161f80f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1bcdebefd547442194ee5ce61d35bd2f"}},"c46b34c68bc34a519c9e0b39352b28b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19008fc8d5164ac2a874f7ee36244fa1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:12&lt;00:00, 35.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53026f2b11bf40fc8a9341fe8eda011c"}},"3ded4c13a32f4fdda7a269e22161f80f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1bcdebefd547442194ee5ce61d35bd2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19008fc8d5164ac2a874f7ee36244fa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53026f2b11bf40fc8a9341fe8eda011c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e834216b7cab4691a15cbb97b671d10a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f70d01135bf04e04aa79543f686189e7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8671046a2a784e9495f547f0992dea36","IPY_MODEL_d3d73c45a3d04d368ab10c2bbe44d150"]}},"f70d01135bf04e04aa79543f686189e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8671046a2a784e9495f547f0992dea36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2da7131622b04d209095dd8bdf7d5666","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":665,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":665,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_127491bbb49c46e1aa8750411c146548"}},"d3d73c45a3d04d368ab10c2bbe44d150":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d1b6ed10c64455e95016d8d41c61870","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 665/665 [00:00&lt;00:00, 2.22kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_771c07263e444d4882b2b2ac1f352a93"}},"2da7131622b04d209095dd8bdf7d5666":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"127491bbb49c46e1aa8750411c146548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d1b6ed10c64455e95016d8d41c61870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"771c07263e444d4882b2b2ac1f352a93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"2hUOye1EV03_"},"source":["# Huggingface Bert for sentence classification\n","\n","Goal: We inherit `class BertPreTrainedModel` and build upon `class BertModel` to create a sentence classifier.\n","\n","Steps:\n","* Use BertModel to obtain hidden sequence of the last layer of a transformer stack, giving tensor H of shape (B,N,D) .\n","* Pick the 0-th position to obtain hidden states at [CLS]position, giving (B,D), as $H_{[CLS]}$.\n","* Project [CLS] hidden states non-linearly with tanh() activation, i.e. $H'_{[CLS]} = tanh(W_{feat} H_{[CLS]} + b_{feat})$.\n","* Apply dropout on $H'_{[CLS]}$.\n","* Finally, project $H'_{[CLS]}$ into output class logits, i.e. $Z = W_o H'_{[CLS]} + b_o$. Shape of $Z$ is (B, C) where $C$ denotes number of output classes.\n","* Class prediction probs $\\hat{Y} = Softmax(Z)$. Shape of $\\hat{Y}$ is (B,C).\n","* As usual, we minimize cross entropy loss to fine-tune all parameters of the model, including BERT."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1d16MTQqigvp","executionInfo":{"status":"ok","timestamp":1618474842523,"user_tz":-480,"elapsed":12199,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"b6038150-c21b-48a1-f933-af17c8e6d8ad"},"source":["!pip install transformers datasets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 2.9MB/s \n","\u001b[?25hCollecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/43b396481a8298c6010afb93b3c1e71d4ba6f8c10797a7da8eb005e45081/datasets-1.5.0-py3-none-any.whl (192kB)\n","\u001b[K     |████████████████████████████████| 194kB 17.8MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 13.1MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n","\u001b[K     |████████████████████████████████| 870kB 30.9MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.0)\n","Collecting huggingface-hub<0.1.0\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 36.0MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Collecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n","\u001b[K     |████████████████████████████████| 112kB 37.1MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=ba60ae995091810d91f72fc58ee44d38b8b287f76df02a87d6130ba1e43ea1d4\n","  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers, huggingface-hub, xxhash, fsspec, datasets\n","Successfully installed datasets-1.5.0 fsspec-0.9.0 huggingface-hub-0.0.8 sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.1 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EuFXbLoSv9uR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474842524,"user_tz":-480,"elapsed":12187,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"24b688dc-16bb-4a2a-da2b-9043124be1d4"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Apr 15 08:20:42 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fJFR7rMN9Lny"},"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoConfig, AutoTokenizer, AutoModel, BertPreTrainedModel, BertModel\n","\n","class BertClassifier(BertPreTrainedModel):\n","  def __init__(self, config):\n","    super().__init__(config)\n","    self._config = config\n","    self._bert = BertModel(config, add_pooling_layer=False)\n","    self._pooler = nn.Linear(config.hidden_size, config.hidden_size)\n","    self._activation = nn.Tanh()\n","    self._dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","    print(\"Config: D={} C={}\".format(config.hidden_size, config.num_labels))\n","    self._classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","    # init weights\n","    self.init_weights()\n","\n","  def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, \n","              output_attentions=None, output_hidden_states=None):\n","    # feed-forward inputs into Bert, producing outputs\n","    outputs = self._bert(input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids,\n","                         position_ids=position_ids,\n","                         output_attentions=output_attentions, \n","                         output_hidden_states=output_hidden_states)\n","\n","    # outputs are tuple of objects of the following:\n","    # outputs[0]: sequence_output at the last layer (i.e. all the hidden vectors at each word position)\n","    # outputs[1]: [CLS] representation followed by non-linear project using tanh if add_pooling_layer=True. Otherwise None here\n","    # outputs[2]: next decoder cache (not applied here)\n","    # outputs[3]: hidden states of all layers (You can inspect hidden states at lower layers for analysis)\n","    # outputs[4]: self-attention probs of all layers.\n","    # outputs[5]: cross-attention probs of all layers (if BERT is used as a decoder in the context of\n","    # sequence to sequence models, where encoder provides some encoded embeddings. Then decoder cross-attend\n","    # the encoder embeddings.). Not applied here.\n","\n","    # obtain sequence output of the last transformer layer (B,N,D=768)\n","    hidden_states = outputs[0]\n","\n","    # obtain [CLS] hidden vector at 0th position: Resulting shape is (B,D)\n","    # We treat [CLS] hidden vector as contextualized sentence embedding features \n","    cls_hidden_states = hidden_states[:,0]\n","\n","    # pass [CLS] hidden state to another hidden layer and obtain non-linear transformed feature\n","    pooled_output = self._activation(self._pooler(cls_hidden_states))\n","\n","    # apply dropout on [CLS]\n","    pooled_output = self._dropout(pooled_output)\n","\n","    # project hidden size to output class size\n","    logits = self._classifier(pooled_output)\n","\n","    # return logits (B, Num classes)\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSHrTdXakkSo","colab":{"base_uri":"https://localhost:8080/","height":392,"referenced_widgets":["aba78168ddc34bfb89046f5c5907cfdf","d4e312228a804ded991d18fc6923cd13","d91468761b514d7786cc608f21ac1d9e","cac6513fd8ee44d9b2e6198ea0a9e10f","a24bb805715549c39df11c1c4e7bd825","75cc15f010a7455db680185a592e06ef","7fc94fb260a443b0a6d95eb58f9ab600","227807e216ab4423b6e0b74b1b315752","bf1e8d518b42471eaa218c08c67db61e","ac661961cd5149f695626e12b01349f5","c9236e79f08c4fe78a0d729ebfb2f1b1","8f68f723318e483595b9a0b8656c7bca","1242015429f441a691891e89fff1b6c1","094b7cf8989c443ba84c8a743c47540e","17c92e5b084e46e0b3d3a7f5e4093f56","bc5bca2ff7174411843c44de011fca3a","5519c8b78cfb45e78ee94adb18ba6674","5c1abdb98f644abbab14428defeb1625","8db7887266a84b6d9089c961adf121cc","6615fddc83ae401bbca013ee4fc8e6f8","6490e2c3997c496c8182237790c8170c","2810194798a94d36818d35bf48bf0d60","f1e3bdf0d7a34b359e2a03d782098e97","fb05c012d1424a8394e302d76f560fb8","4408c96aa46d446d9fd03bdaab1d0705","7dd790503f4244708d11e77ab8b37103","e7fcb8a54f1f4a50ab3418de1af07201","1fc8d8f682c84bec80192f8026437727","14713e8482ce4268a6d2691f5d10f3d6","f72923edaee244799bd4d288c0ce047a","e728dc54cb0c4159b467666e6e8e881f","b11a5359c03341c8995ff5e62d4b5b4e","948fbb8fd4554c65bb4d2b9e5793bfcd","6bdd72fc2e0d4dd4b60b5dc0eedf22c7","14e68033d30b4fab8bff1b3057211f80","c46b34c68bc34a519c9e0b39352b28b9","3ded4c13a32f4fdda7a269e22161f80f","1bcdebefd547442194ee5ce61d35bd2f","19008fc8d5164ac2a874f7ee36244fa1","53026f2b11bf40fc8a9341fe8eda011c"]},"executionInfo":{"status":"ok","timestamp":1618474882339,"user_tz":-480,"elapsed":51989,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"6e55997d-5933-4131-c122-308b31957103"},"source":["# select the BERT model you are interested in.\n","# Supported BERT model names are:\n","BERT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n","    \"bert-base-uncased\",\n","    \"bert-large-uncased\",\n","    \"bert-base-cased\",\n","    \"bert-large-cased\",\n","    \"bert-base-multilingual-uncased\",\n","    \"bert-base-multilingual-cased\",\n","    \"bert-base-chinese\",\n","    \"bert-base-german-cased\",\n","    \"bert-large-uncased-whole-word-masking\",\n","    \"bert-large-cased-whole-word-masking\",\n","    \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n","    \"bert-large-cased-whole-word-masking-finetuned-squad\",\n","    \"bert-base-cased-finetuned-mrpc\",\n","    \"bert-base-german-dbmdz-cased\",\n","    \"bert-base-german-dbmdz-uncased\",\n","    \"cl-tohoku/bert-base-japanese\",\n","    \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n","    \"cl-tohoku/bert-base-japanese-char\",\n","    \"cl-tohoku/bert-base-japanese-char-whole-word-masking\",\n","    \"TurkuNLP/bert-base-finnish-cased-v1\",\n","    \"TurkuNLP/bert-base-finnish-uncased-v1\",\n","    \"wietsedv/bert-base-dutch-cased\",\n","    # See all BERT models at https://huggingface.co/models?filter=bert\n","]\n","\n","# Let's use the basic English version here\n","model_name = BERT_PRETRAINED_MODEL_ARCHIVE_LIST[0]\n","\n","# Create the corresponding BERT config, tokenizer, and BERT model with pretrained weights\n","config = AutoConfig.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Let's set 2 class labels assuming we want to do Question-Question similarity\n","config.num_labels = 2\n","model = BertClassifier.from_pretrained(model_name, config=config).to(\"cuda:0\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aba78168ddc34bfb89046f5c5907cfdf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf1e8d518b42471eaa218c08c67db61e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5519c8b78cfb45e78ee94adb18ba6674","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4408c96aa46d446d9fd03bdaab1d0705","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"948fbb8fd4554c65bb4d2b9e5793bfcd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Config: D=768 C=2\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassifier: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias']\n","- This IS expected if you are initializing BertClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert._bert.embeddings.word_embeddings.weight', 'bert._bert.embeddings.position_embeddings.weight', 'bert._bert.embeddings.token_type_embeddings.weight', 'bert._bert.embeddings.LayerNorm.weight', 'bert._bert.embeddings.LayerNorm.bias', 'bert._bert.encoder.layer.0.attention.self.query.weight', 'bert._bert.encoder.layer.0.attention.self.query.bias', 'bert._bert.encoder.layer.0.attention.self.key.weight', 'bert._bert.encoder.layer.0.attention.self.key.bias', 'bert._bert.encoder.layer.0.attention.self.value.weight', 'bert._bert.encoder.layer.0.attention.self.value.bias', 'bert._bert.encoder.layer.0.attention.output.dense.weight', 'bert._bert.encoder.layer.0.attention.output.dense.bias', 'bert._bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.0.intermediate.dense.weight', 'bert._bert.encoder.layer.0.intermediate.dense.bias', 'bert._bert.encoder.layer.0.output.dense.weight', 'bert._bert.encoder.layer.0.output.dense.bias', 'bert._bert.encoder.layer.0.output.LayerNorm.weight', 'bert._bert.encoder.layer.0.output.LayerNorm.bias', 'bert._bert.encoder.layer.1.attention.self.query.weight', 'bert._bert.encoder.layer.1.attention.self.query.bias', 'bert._bert.encoder.layer.1.attention.self.key.weight', 'bert._bert.encoder.layer.1.attention.self.key.bias', 'bert._bert.encoder.layer.1.attention.self.value.weight', 'bert._bert.encoder.layer.1.attention.self.value.bias', 'bert._bert.encoder.layer.1.attention.output.dense.weight', 'bert._bert.encoder.layer.1.attention.output.dense.bias', 'bert._bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.1.intermediate.dense.weight', 'bert._bert.encoder.layer.1.intermediate.dense.bias', 'bert._bert.encoder.layer.1.output.dense.weight', 'bert._bert.encoder.layer.1.output.dense.bias', 'bert._bert.encoder.layer.1.output.LayerNorm.weight', 'bert._bert.encoder.layer.1.output.LayerNorm.bias', 'bert._bert.encoder.layer.2.attention.self.query.weight', 'bert._bert.encoder.layer.2.attention.self.query.bias', 'bert._bert.encoder.layer.2.attention.self.key.weight', 'bert._bert.encoder.layer.2.attention.self.key.bias', 'bert._bert.encoder.layer.2.attention.self.value.weight', 'bert._bert.encoder.layer.2.attention.self.value.bias', 'bert._bert.encoder.layer.2.attention.output.dense.weight', 'bert._bert.encoder.layer.2.attention.output.dense.bias', 'bert._bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.2.intermediate.dense.weight', 'bert._bert.encoder.layer.2.intermediate.dense.bias', 'bert._bert.encoder.layer.2.output.dense.weight', 'bert._bert.encoder.layer.2.output.dense.bias', 'bert._bert.encoder.layer.2.output.LayerNorm.weight', 'bert._bert.encoder.layer.2.output.LayerNorm.bias', 'bert._bert.encoder.layer.3.attention.self.query.weight', 'bert._bert.encoder.layer.3.attention.self.query.bias', 'bert._bert.encoder.layer.3.attention.self.key.weight', 'bert._bert.encoder.layer.3.attention.self.key.bias', 'bert._bert.encoder.layer.3.attention.self.value.weight', 'bert._bert.encoder.layer.3.attention.self.value.bias', 'bert._bert.encoder.layer.3.attention.output.dense.weight', 'bert._bert.encoder.layer.3.attention.output.dense.bias', 'bert._bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.3.intermediate.dense.weight', 'bert._bert.encoder.layer.3.intermediate.dense.bias', 'bert._bert.encoder.layer.3.output.dense.weight', 'bert._bert.encoder.layer.3.output.dense.bias', 'bert._bert.encoder.layer.3.output.LayerNorm.weight', 'bert._bert.encoder.layer.3.output.LayerNorm.bias', 'bert._bert.encoder.layer.4.attention.self.query.weight', 'bert._bert.encoder.layer.4.attention.self.query.bias', 'bert._bert.encoder.layer.4.attention.self.key.weight', 'bert._bert.encoder.layer.4.attention.self.key.bias', 'bert._bert.encoder.layer.4.attention.self.value.weight', 'bert._bert.encoder.layer.4.attention.self.value.bias', 'bert._bert.encoder.layer.4.attention.output.dense.weight', 'bert._bert.encoder.layer.4.attention.output.dense.bias', 'bert._bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.4.intermediate.dense.weight', 'bert._bert.encoder.layer.4.intermediate.dense.bias', 'bert._bert.encoder.layer.4.output.dense.weight', 'bert._bert.encoder.layer.4.output.dense.bias', 'bert._bert.encoder.layer.4.output.LayerNorm.weight', 'bert._bert.encoder.layer.4.output.LayerNorm.bias', 'bert._bert.encoder.layer.5.attention.self.query.weight', 'bert._bert.encoder.layer.5.attention.self.query.bias', 'bert._bert.encoder.layer.5.attention.self.key.weight', 'bert._bert.encoder.layer.5.attention.self.key.bias', 'bert._bert.encoder.layer.5.attention.self.value.weight', 'bert._bert.encoder.layer.5.attention.self.value.bias', 'bert._bert.encoder.layer.5.attention.output.dense.weight', 'bert._bert.encoder.layer.5.attention.output.dense.bias', 'bert._bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.5.intermediate.dense.weight', 'bert._bert.encoder.layer.5.intermediate.dense.bias', 'bert._bert.encoder.layer.5.output.dense.weight', 'bert._bert.encoder.layer.5.output.dense.bias', 'bert._bert.encoder.layer.5.output.LayerNorm.weight', 'bert._bert.encoder.layer.5.output.LayerNorm.bias', 'bert._bert.encoder.layer.6.attention.self.query.weight', 'bert._bert.encoder.layer.6.attention.self.query.bias', 'bert._bert.encoder.layer.6.attention.self.key.weight', 'bert._bert.encoder.layer.6.attention.self.key.bias', 'bert._bert.encoder.layer.6.attention.self.value.weight', 'bert._bert.encoder.layer.6.attention.self.value.bias', 'bert._bert.encoder.layer.6.attention.output.dense.weight', 'bert._bert.encoder.layer.6.attention.output.dense.bias', 'bert._bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.6.intermediate.dense.weight', 'bert._bert.encoder.layer.6.intermediate.dense.bias', 'bert._bert.encoder.layer.6.output.dense.weight', 'bert._bert.encoder.layer.6.output.dense.bias', 'bert._bert.encoder.layer.6.output.LayerNorm.weight', 'bert._bert.encoder.layer.6.output.LayerNorm.bias', 'bert._bert.encoder.layer.7.attention.self.query.weight', 'bert._bert.encoder.layer.7.attention.self.query.bias', 'bert._bert.encoder.layer.7.attention.self.key.weight', 'bert._bert.encoder.layer.7.attention.self.key.bias', 'bert._bert.encoder.layer.7.attention.self.value.weight', 'bert._bert.encoder.layer.7.attention.self.value.bias', 'bert._bert.encoder.layer.7.attention.output.dense.weight', 'bert._bert.encoder.layer.7.attention.output.dense.bias', 'bert._bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.7.intermediate.dense.weight', 'bert._bert.encoder.layer.7.intermediate.dense.bias', 'bert._bert.encoder.layer.7.output.dense.weight', 'bert._bert.encoder.layer.7.output.dense.bias', 'bert._bert.encoder.layer.7.output.LayerNorm.weight', 'bert._bert.encoder.layer.7.output.LayerNorm.bias', 'bert._bert.encoder.layer.8.attention.self.query.weight', 'bert._bert.encoder.layer.8.attention.self.query.bias', 'bert._bert.encoder.layer.8.attention.self.key.weight', 'bert._bert.encoder.layer.8.attention.self.key.bias', 'bert._bert.encoder.layer.8.attention.self.value.weight', 'bert._bert.encoder.layer.8.attention.self.value.bias', 'bert._bert.encoder.layer.8.attention.output.dense.weight', 'bert._bert.encoder.layer.8.attention.output.dense.bias', 'bert._bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.8.intermediate.dense.weight', 'bert._bert.encoder.layer.8.intermediate.dense.bias', 'bert._bert.encoder.layer.8.output.dense.weight', 'bert._bert.encoder.layer.8.output.dense.bias', 'bert._bert.encoder.layer.8.output.LayerNorm.weight', 'bert._bert.encoder.layer.8.output.LayerNorm.bias', 'bert._bert.encoder.layer.9.attention.self.query.weight', 'bert._bert.encoder.layer.9.attention.self.query.bias', 'bert._bert.encoder.layer.9.attention.self.key.weight', 'bert._bert.encoder.layer.9.attention.self.key.bias', 'bert._bert.encoder.layer.9.attention.self.value.weight', 'bert._bert.encoder.layer.9.attention.self.value.bias', 'bert._bert.encoder.layer.9.attention.output.dense.weight', 'bert._bert.encoder.layer.9.attention.output.dense.bias', 'bert._bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.9.intermediate.dense.weight', 'bert._bert.encoder.layer.9.intermediate.dense.bias', 'bert._bert.encoder.layer.9.output.dense.weight', 'bert._bert.encoder.layer.9.output.dense.bias', 'bert._bert.encoder.layer.9.output.LayerNorm.weight', 'bert._bert.encoder.layer.9.output.LayerNorm.bias', 'bert._bert.encoder.layer.10.attention.self.query.weight', 'bert._bert.encoder.layer.10.attention.self.query.bias', 'bert._bert.encoder.layer.10.attention.self.key.weight', 'bert._bert.encoder.layer.10.attention.self.key.bias', 'bert._bert.encoder.layer.10.attention.self.value.weight', 'bert._bert.encoder.layer.10.attention.self.value.bias', 'bert._bert.encoder.layer.10.attention.output.dense.weight', 'bert._bert.encoder.layer.10.attention.output.dense.bias', 'bert._bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.10.intermediate.dense.weight', 'bert._bert.encoder.layer.10.intermediate.dense.bias', 'bert._bert.encoder.layer.10.output.dense.weight', 'bert._bert.encoder.layer.10.output.dense.bias', 'bert._bert.encoder.layer.10.output.LayerNorm.weight', 'bert._bert.encoder.layer.10.output.LayerNorm.bias', 'bert._bert.encoder.layer.11.attention.self.query.weight', 'bert._bert.encoder.layer.11.attention.self.query.bias', 'bert._bert.encoder.layer.11.attention.self.key.weight', 'bert._bert.encoder.layer.11.attention.self.key.bias', 'bert._bert.encoder.layer.11.attention.self.value.weight', 'bert._bert.encoder.layer.11.attention.self.value.bias', 'bert._bert.encoder.layer.11.attention.output.dense.weight', 'bert._bert.encoder.layer.11.attention.output.dense.bias', 'bert._bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert._bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert._bert.encoder.layer.11.intermediate.dense.weight', 'bert._bert.encoder.layer.11.intermediate.dense.bias', 'bert._bert.encoder.layer.11.output.dense.weight', 'bert._bert.encoder.layer.11.output.dense.bias', 'bert._bert.encoder.layer.11.output.LayerNorm.weight', 'bert._bert.encoder.layer.11.output.LayerNorm.bias', 'bert._pooler.weight', 'bert._pooler.bias', 'bert._classifier.weight', 'bert._classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OegOyawnaMb","executionInfo":{"status":"ok","timestamp":1618474882341,"user_tz":-480,"elapsed":51987,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"c73cbece-38d7-486e-b2e0-f9119d2a91d0"},"source":["print(config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xKC_QZ2pw_zY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474882342,"user_tz":-480,"elapsed":51979,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"2bff694d-cff8-4019-c4d8-d4e2a172cdad"},"source":["print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BertClassifier(\n","  (_bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (_pooler): Linear(in_features=768, out_features=768, bias=True)\n","  (_activation): Tanh()\n","  (_dropout): Dropout(p=0.1, inplace=False)\n","  (_classifier): Linear(in_features=768, out_features=2, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VmGjZiTpz_5P"},"source":["### Demo to obtain model parameters from state dict"]},{"cell_type":"code","metadata":{"id":"OTWIXLUEyeEO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474884163,"user_tz":-480,"elapsed":53790,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"2fabcb78-fee3-4f4d-c362-eca75312610a"},"source":["#for p in model.named_parameters():\n","#  print(p)\n","\n","state_dict = model.state_dict()\n","state_dict.keys()\n","\n","# inspect word embeddings\n","word_embedding = state_dict['_bert.embeddings.word_embeddings.weight']\n","\n","# copy word embeddding matrix from GPU to CPU, then cast the object into numpy array\n","word_embedding_np = word_embedding.cpu().numpy()\n","\n","print(word_embedding_np.shape)\n","print(word_embedding_np[2001][:20])\n","\n","# decode word index 2001 to string\n","print(tokenizer.decode(2001))\n","\n","vocab_map = []\n","for j in range(len(tokenizer)):\n","  vocab_map.append(tokenizer.decode(j))\n","\n","print(vocab_map[2002])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(30522, 768)\n","[ 1.5728038e-02  1.8885795e-02  1.1909006e-02  4.2030605e-04\n","  4.8940949e-04  8.7801656e-03  5.7248515e-03  9.3500698e-03\n"," -2.7436389e-02  1.3847560e-02 -2.8802561e-02  1.5211003e-02\n","  3.5635892e-02 -1.3782515e-02 -2.7663313e-02  2.7918646e-02\n"," -7.1793147e-05  1.0890171e-02 -2.3118103e-02 -1.8425690e-02]\n","was\n","he\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O7Bf0kQV4MSV"},"source":["## Bert tokenizer\n","\n","It takes list of string (for encoding sentence A only), list of string tuple (for encoding sentence A and sentence B).\n","\n","It does many things for you, including input_ids, padding, attention masking, and token_type_ids!\n","\n","If add_special_tokens is set to True, [CLS] and [SEP] will be added automatically."]},{"cell_type":"code","metadata":{"id":"QZFRBhPBYE6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474884164,"user_tz":-480,"elapsed":53776,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"2336a54f-541c-4d93-9730-b661ddd2c839"},"source":["# Batch size = 2\n","output = tokenizer([(\"a cat sat on a mat\", \"a mat has a cat sat on it\"), \n","                    (\"how is the weather today\", \"what is the status of weather yesterday\"),\n","                   ], padding=True, add_special_tokens=True)\n","                   \n","print(output.keys())\n","print(output[\"input_ids\"])\n","print(output[\"attention_mask\"])\n","print(output[\"token_type_ids\"])\n","print(tokenizer.batch_decode(output[\"input_ids\"]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","[[101, 1037, 4937, 2938, 2006, 1037, 13523, 102, 1037, 13523, 2038, 1037, 4937, 2938, 2006, 2009, 102], [101, 2129, 2003, 1996, 4633, 2651, 102, 2054, 2003, 1996, 3570, 1997, 4633, 7483, 102, 0, 0]]\n","[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]\n","[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]\n","['[CLS] a cat sat on a mat [SEP] a mat has a cat sat on it [SEP]', '[CLS] how is the weather today [SEP] what is the status of weather yesterday [SEP] [PAD] [PAD]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d6J0H_-i5F6A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474884165,"user_tz":-480,"elapsed":53759,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"24525ed5-0c54-4464-f754-4f5d39c87572"},"source":["input_ids = torch.tensor(output[\"input_ids\"], dtype=torch.int32).to(\"cuda:0\")\n","attention_mask = torch.tensor(output[\"attention_mask\"], dtype=torch.int32).to(\"cuda:0\")\n","token_type_ids = torch.tensor(output[\"token_type_ids\"], dtype=torch.int32).to(\"cuda:0\")\n","print(input_ids)\n","print(attention_mask)\n","print(token_type_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[  101,  1037,  4937,  2938,  2006,  1037, 13523,   102,  1037, 13523,\n","          2038,  1037,  4937,  2938,  2006,  2009,   102],\n","        [  101,  2129,  2003,  1996,  4633,  2651,   102,  2054,  2003,  1996,\n","          3570,  1997,  4633,  7483,   102,     0,     0]], device='cuda:0',\n","       dtype=torch.int32)\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0',\n","       dtype=torch.int32)\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0',\n","       dtype=torch.int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b7wV3_vMwXV8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474884166,"user_tz":-480,"elapsed":53747,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"6724639b-0230-457b-997c-90cc4b39a583"},"source":["logits = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","print(logits)\n","print(logits.size()) # shape: (B, C)\n","print(config.num_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0.0243, 0.6621],\n","        [0.0389, 0.6171]], device='cuda:0', grad_fn=<AddmmBackward>)\n","torch.Size([2, 2])\n","2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6wV3PCQU4Bvl"},"source":["### Load sentiment data"]},{"cell_type":"markdown","metadata":{"id":"iInzBkNZ4Fs3"},"source":["You may refer to previous homework assignments of how to create a torch Dataset and Dataloaders to obtain a batch of inputs.\n","\n","Then you minimize the cross entropy loss as demonstrated in homework assignments."]},{"cell_type":"code","metadata":{"id":"wgShn_W74AnP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vV1HJvvNb4oy"},"source":["# Bert for token classification\n","\n","This applies to applications such as NER and part-of-speech tagging task."]},{"cell_type":"code","metadata":{"id":"6jbQGk0AcEX6"},"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoConfig, AutoTokenizer, AutoModel, BertPreTrainedModel, BertModel\n","\n","class BertTagger(BertPreTrainedModel):\n","  def __init__(self, config):\n","    super().__init__(config)\n","    self._config = config\n","    self._bert = BertModel(config, add_pooling_layer=False)\n","    self._dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","    print(\"Config: D={} C={}\".format(config.hidden_size, config.num_labels))\n","    self._classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","    # init weights\n","    self.init_weights()\n","\n","  def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, \n","              output_attentions=None, output_hidden_states=None):\n","    # feed-forward inputs into Bert, producing outputs\n","    outputs = self._bert(input_ids, \n","                         attention_mask=attention_mask, \n","                         token_type_ids=token_type_ids,\n","                         position_ids=position_ids,\n","                         output_attentions=output_attentions, \n","                         output_hidden_states=output_hidden_states)\n","\n","    # outputs are tuple of objects of the following:\n","    # outputs[0]: sequence_output at the last layer (i.e. all the hidden vectors at each word position)\n","    # outputs[1]: [CLS] representation followed by non-linear project using tanh if add_pooling_layer=True. Otherwise None here\n","    # outputs[2]: next decoder cache (not applied here)\n","    # outputs[3]: hidden states of all layers (You can inspect hidden states at lower layers for analysis)\n","    # outputs[4]: self-attention probs of all layers.\n","    # outputs[5]: cross-attention probs of all layers (if BERT is used as a decoder in the context of\n","    # sequence to sequence models, where encoder provides some encoded embeddings. Then decoder cross-attend\n","    # the encoder embeddings.). Not applied here.\n","\n","    # obtain sequence output of the last transformer layer (B,N,D=768)\n","    hidden_states = outputs[0]\n","\n","    # apply dropout\n","    hidden_states = self._dropout(hidden_states)\n","\n","    # project hidden size to output class size\n","    logits = self._classifier(hidden_states)\n","\n","    # return logits (B, N, Num classes)\n","    # each word position contains a distribution of score for each output class\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-E7lQPL7adyF"},"source":["# Customize Huggingface model configuration\n","\n","In some cases, you want to use the Huggingface's deep models such as BERT, GPT2, Roberta etc and you want to customize the modeling structure such as having a fewer transformer layers, fewer hidden dimensions and so on. You can definitely do so by modifying the AutoConfig object. \n","\n","BUT, you need to train your model from scatch."]},{"cell_type":"code","metadata":{"id":"a0UxtH6Nbdwf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474884169,"user_tz":-480,"elapsed":53737,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"5e1272c9-b5b1-4709-b052-9dd1f6648a64"},"source":["print(config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xLiYeVJalCYx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474884170,"user_tz":-480,"elapsed":53734,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"ebdafdaf-0d53-42a2-ae30-804cbfecb88a"},"source":["# my customized vocabulary size\n","config.vocab_size = 5000\n","\n","# 2 transformer layers\n","config.num_hidden_layers = 2\n","\n","# hidden dimension is 200\n","config.hidden_size = 192\n","\n","# number of heads in MultiHead attention. Must be able to divide config.hidden_size\n","config.num_attention_heads = 4\n","\n","# parameter in Transformer\n","config.intermediate_size = 192\n","\n","# print the modified config\n","print(config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 192,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 192,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 4,\n","  \"num_hidden_layers\": 2,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 5000\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E9jZNy-9FQue"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fFamMa8k1w4m"},"source":["### Customize GPT2 model for language modeling purpose"]},{"cell_type":"code","metadata":{"id":"eC-zv548laQT","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["e834216b7cab4691a15cbb97b671d10a","f70d01135bf04e04aa79543f686189e7","8671046a2a784e9495f547f0992dea36","d3d73c45a3d04d368ab10c2bbe44d150","2da7131622b04d209095dd8bdf7d5666","127491bbb49c46e1aa8750411c146548","0d1b6ed10c64455e95016d8d41c61870","771c07263e444d4882b2b2ac1f352a93"]},"executionInfo":{"status":"ok","timestamp":1618474885755,"user_tz":-480,"elapsed":55310,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"e1c128a8-7519-481b-9671-9cfd3c3a3ce6"},"source":["from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n","\n","# create a model from scratch according to gpt_config for causal language modeling\n","gpt_config = AutoConfig.from_pretrained(\"gpt2\")\n","print(gpt_config)\n","#gpt_model = AutoModelForCausalLM.from_config(config=gpt_config)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e834216b7cab4691a15cbb97b671d10a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.5.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qvd_koT02eu2"},"source":["gpt_config.vocab_size = 20001\n","gpt_model = AutoModelForCausalLM.from_config(config=gpt_config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qM6tagdKQav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618474889788,"user_tz":-480,"elapsed":59335,"user":{"displayName":"Yik-Cheung Tam","photoUrl":"","userId":"08154216466222084578"}},"outputId":"47b965ba-ba4d-4609-87a1-f799e5e58d42"},"source":["# see what is inside. Better check out documentation from Huggingface\n","print(gpt_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(20001, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=20001, bias=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AExSN61f2t1T"},"source":["You see that the lm_head to predict the next word now has 20001 output vocabulary for prediction."]},{"cell_type":"code","metadata":{"id":"D--KUHke2pj9"},"source":[""],"execution_count":null,"outputs":[]}]}